{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32yCsRUo8H33"
   },
   "source": [
    "# 2025 COMP90042 Project\n",
    "*Make sure you change the file name with your group id.*\n",
    "\n",
    "**MelMoxue Bruce**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCybYoGz8YWQ"
   },
   "source": [
    "# Readme\n",
    "*If there is something to be noted for the marker, please mention here.*\n",
    "\n",
    "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*\n",
    "\n",
    "**This file inlcudes the deep learning method, i.e., gru, transformer to find the relevant evidence.**\n",
    "\n",
    "**This method needs to train.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6po98qVA8bJD"
   },
   "source": [
    "# 1.DataSet Processing\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qvff21Hv8zjk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1228 train claims.\n",
      "Loaded 154 dev claims.\n",
      "Loaded 153 test claims.\n",
      "Loaded 1208827 evidence documents.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Set paths\n",
    "data_dir = \"data\"\n",
    "train_claims_file = os.path.join(data_dir, \"train-claims.json\")\n",
    "dev_claims_file = os.path.join(data_dir, \"dev-claims.json\")\n",
    "test_claims_file = os.path.join(data_dir, \"test-claims-unlabelled.json\")\n",
    "evidence_file = os.path.join(data_dir, \"evidence.json\")\n",
    "\n",
    "# Load train claims\n",
    "with open(train_claims_file, 'r') as f:\n",
    "    train_claims = json.load(f)\n",
    "train_ids = list(train_claims.keys())\n",
    "train_texts = [train_claims[claim_id]['claim_text'] for claim_id in train_ids]\n",
    "claim_id_to_train_inidce = {claim_id: i for i, claim_id in enumerate(train_ids)}\n",
    "\n",
    "print(f\"Loaded {len(train_claims)} train claims.\")\n",
    "\n",
    "# Load dev claims\n",
    "with open(dev_claims_file, 'r') as f:\n",
    "    dev_claims = json.load(f)\n",
    "dev_ids = list(dev_claims.keys())\n",
    "dev_texts = [dev_claims[claim_id]['claim_text'] for claim_id in dev_ids]\n",
    "    \n",
    "print(f\"Loaded {len(dev_claims)} dev claims.\")\n",
    "\n",
    "# Load test claims\n",
    "with open(test_claims_file, 'r') as f:\n",
    "    test_claims = json.load(f)\n",
    "test_texts = [test_claims[claim_id]['claim_text'] for claim_id in test_claims.keys()]\n",
    "\n",
    "print(f\"Loaded {len(test_claims)} test claims.\")\n",
    "\n",
    "# Load evidence texts\n",
    "with open(evidence_file, 'r') as f:\n",
    "    evidence = json.load(f)\n",
    "\n",
    "evidence_ids = list(evidence.keys())\n",
    "evidence_texts = [evidence[claim_id] for claim_id in evidence_ids]\n",
    "evidence_id_to_train_index = {claim_id: i for i, claim_id in enumerate(evidence_ids)}\n",
    "print(f\"Loaded {len(evidence)} evidence documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 112508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208827/1208827 [01:16<00:00, 15805.83it/s]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "# function to yield the tokens from the data\n",
    "def yield_tokens(data):\n",
    "    for item in data:\n",
    "        tokens = word_tokenize(item.lower())\n",
    "        yield tokens\n",
    "\n",
    "# build the vocabulary from the data\n",
    "from collections import Counter\n",
    "def build_vocab_from_iterator(iterator, min_freq=5, special_tokens=(\"<pad>\", \"<unk>\", \"<cls>\")):\n",
    "    \"\"\"Build a vocabulary from an iterator of token lists.\"\"\"\n",
    "    counter = Counter()\n",
    "    for tokens in iterator:\n",
    "        counter.update(tokens)\n",
    "    vocab = {special_token: idx for idx, special_token in enumerate(special_tokens)}\n",
    "    cur_idx = len(special_tokens)\n",
    "    for idx, (token, freq) in enumerate(counter.items()):\n",
    "        if freq >= min_freq:\n",
    "            vocab[token] = cur_idx\n",
    "            cur_idx += 1\n",
    "    \n",
    "    # index to token mapping\n",
    "    idx_to_token = {idx: token for token, idx in vocab.items()}\n",
    "    return vocab, idx_to_token\n",
    "\n",
    "# Create the vocabulary for train, evidence\n",
    "vocab, idx_to_token = build_vocab_from_iterator(yield_tokens(train_texts + evidence_texts))\n",
    "\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "\n",
    "def process_text(text, vocab):\n",
    "    \"\"\"Convert text to indices using the vocabulary.\"\"\"\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return [vocab[\"<cls>\"]] + [vocab.get(token, vocab[\"<unk>\"]) for token in tokens]\n",
    "\n",
    "\n",
    "train_texts_indices = [process_text(text, vocab) for text in train_texts]\n",
    "dev_texts_indices = [process_text(text, vocab) for text in dev_texts]\n",
    "test_texts_indices = [process_text(text, vocab) for text in test_texts]\n",
    "\n",
    "evidence_texts_indices = [process_text(text, vocab) for text in tqdm(evidence_texts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FA2ao2l8hOg"
   },
   "source": [
    "# 2. Model Implementation\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I will define three common NLP deep learning models, including lstm, gru and transformer. And I will show how to train a retrieval model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QIEqDDT78q39"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# BiLSTM with two layers and dropout\n",
    "class BiLSTMEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers=2, dropout=0.2):\n",
    "        super(BiLSTMEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab['<pad>'])\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, \n",
    "                           batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, hidden_dim)  # Bi-directional output\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        # Pack padded sequence for LSTM\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths, batch_first=True, enforce_sorted=False)\n",
    "        output, (hidden, _) = self.lstm(packed)\n",
    "        \n",
    "        # Use the last hidden state from both directions\n",
    "        hidden_forward = hidden[-2, :, :]  # Second to last layer is forward of last layer\n",
    "        hidden_backward = hidden[-1, :, :]  # Last layer is backward of last layer\n",
    "        hidden_concat = torch.cat((hidden_forward, hidden_backward), dim=1)\n",
    "        \n",
    "        # Project to final embedding space\n",
    "        final_embedding = self.fc(hidden_concat)\n",
    "        return final_embedding\n",
    "    \n",
    "\n",
    "# BiGRU with two layers and dropout\n",
    "class BiGRUEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers=2, dropout=0.2):\n",
    "        super(BiGRUEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab['<pad>'])\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=num_layers, \n",
    "                          batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, hidden_dim)  # Bi-directional output\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        # Pack padded sequence for GRU\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths, batch_first=True, enforce_sorted=False)\n",
    "        output, hidden = self.gru(packed)\n",
    "        \n",
    "        # Use the last hidden state from both directions\n",
    "        hidden_forward = hidden[-2, :, :]  # Second to last layer is forward of last layer\n",
    "        hidden_backward = hidden[-1, :, :]  # Last layer is backward of last layer\n",
    "        hidden_concat = torch.cat((hidden_forward, hidden_backward), dim=1)\n",
    "        \n",
    "        # Project to final embedding space\n",
    "        final_embedding = self.fc(hidden_concat)\n",
    "        return final_embedding\n",
    "    \n",
    "# Transformer Encoder with cls token in the first position\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_heads, num_layers, hidden_dim, dropout=0.2):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab['<pad>'])\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(1, 1000, embedding_dim))  # Max length of 1000\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_dim, \n",
    "            nhead=num_heads, \n",
    "            dim_feedforward=hidden_dim,\n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(embedding_dim, hidden_dim)  # Project to final embedding space\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        embedded = self.embedding(x) + self.positional_encoding[:, :x.size(1), :]\n",
    "        output = self.transformer_encoder(embedded)\n",
    "        \n",
    "        # Use the first token (CLS token) as the representation for the entire sequence\n",
    "        cls_output = output[:, 0, :]\n",
    "        final_embedding = self.fc(cls_output)\n",
    "        return final_embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will define the loss funciton for one claim with multiple postive evidences and negative evidences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(claim_embedding, pos_evidence_embeddings, neg_evidence_embeddings, temperature=0.1):\n",
    "    \"\"\"Compute contrastive loss for a claim\"\"\"\n",
    "    # Compute positive and negative similarities\n",
    "    pos_sim = torch.exp(torch.matmul(claim_embedding, pos_evidence_embeddings.T) / temperature).sum()\n",
    "    neg_sim = torch.exp(torch.matmul(claim_embedding, neg_evidence_embeddings.T) / temperature).sum()\n",
    "\n",
    "    # Compute contrastive loss\n",
    "    loss = -torch.log(pos_sim / (pos_sim + neg_sim))\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "test code\n",
    "It will calcualte the score in dev dataset.\n",
    "\"\"\"\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_all_embeddings(model, evidence_texts_indices, batch_size=32):\n",
    "    \"\"\"Generate evidence embeddings using the model\"\"\"\n",
    "    all_embeddings = []  # each embedding is a list of indices of evidence documents\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(evidence_texts_indices), batch_size)):\n",
    "            evidence_batch = evidence_texts_indices[i:i+batch_size]\n",
    "            \n",
    "            # Process texts and get lengths\n",
    "            evidence_lengths = [len(text) for text in evidence_batch]\n",
    "            evidence_batch_indices = torch.nn.utils.rnn.pad_sequence([torch.tensor(text) for text in evidence_batch], \n",
    "                                                                     batch_first=True, padding_value=vocab['<pad>'])\n",
    "            # Get embeddings\n",
    "            evidence_embeddings = model(evidence_batch_indices, evidence_lengths)\n",
    "            \n",
    "            # Store embeddings\n",
    "            all_embeddings.extend(evidence_embeddings.tolist())\n",
    "            del evidence_embeddings\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return torch.tensor(all_embeddings)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "def get_test_f_scores(test_texts_indices, test_claims, test_ids, evidence_texts_indices, evidence_indice_to_claim_id, model, batch_size=32):\n",
    "    \"\"\"Get F-scores for test claims\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Generate test claim embeddings\n",
    "    test_claim_embeddings = generate_all_embeddings(model, test_texts_indices, batch_size=batch_size)\n",
    "    norm_test_claim_embeddings = F.normalize(test_claim_embeddings, p=2, dim=1)\n",
    "\n",
    "    # Generate evidence embeddings\n",
    "    evidence_embeddings = generate_all_embeddings(model, evidence_texts_indices, batch_size=batch_size*10)\n",
    "    norm_evidence_embeddings = F.normalize(evidence_embeddings, p=2, dim=1)\n",
    "\n",
    "    # Compute cosine similarities\n",
    "    similarities = torch.matmul(norm_test_claim_embeddings, norm_evidence_embeddings.T)\n",
    "    # Get top-k evidence indices for each claim\n",
    "    \n",
    "    top_k = 5\n",
    "    top_k_indices = torch.topk(similarities, top_k, dim=1).indices\n",
    "    top_k_indices = top_k_indices.numpy()\n",
    "    \n",
    "    # Compute F-scores\n",
    "    f_scores = []\n",
    "    for i, claim_id in tqdm(enumerate(test_ids)):\n",
    "        # Get the evidence indices for the claim\n",
    "        true_evidence_indices = test_claims[claim_id][\"evidences\"]\n",
    "        \n",
    "        # Get the predicted evidence indices\n",
    "        predicted_evidence_indices = top_k_indices[i]\n",
    "        predicted_evidence_indices = [evidence_indice_to_claim_id[evidence_index] for evidence_index in predicted_evidence_indices]\n",
    "        \n",
    "        # Compute precision and recall\n",
    "        true_positives = len(set(true_evidence_indices) & set(predicted_evidence_indices))\n",
    "        precision = true_positives / len(predicted_evidence_indices) if len(predicted_evidence_indices) > 0 else 0.0\n",
    "        recall = true_positives / len(true_evidence_indices) if len(true_evidence_indices) > 0 else 0.0\n",
    "        \n",
    "        # Compute F-score\n",
    "        f_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        f_scores.append(f_score)\n",
    "    model.train()\n",
    "    return np.mean(f_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "Step 1\n",
      "Step 2\n",
      "Step 3\n",
      "Step 4\n",
      "Step 5\n",
      "Step 6\n",
      "Step 7\n",
      "Step 8\n",
      "Step 9\n",
      "Step 10\n",
      "Step 11\n",
      "Step 12\n",
      "Step 13\n",
      "Step 14\n",
      "Step 15\n",
      "Step 16\n",
      "Step 17\n",
      "Step 18\n",
      "Step 19\n",
      "Step 20\n",
      "Loss: 3.5200395584106445\n",
      "Step 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 41.26it/s]\n",
      "100%|██████████| 3778/3778 [04:09<00:00, 15.17it/s]\n",
      "154it [00:00, 144275.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score on dev set: 0.005009276437847867\n",
      "New best F-score: 0.005009276437847867\n",
      "Step 22\n",
      "Step 23\n",
      "Step 24\n",
      "Step 25\n",
      "Step 26\n",
      "Step 27\n",
      "Step 28\n",
      "Step 29\n",
      "Step 30\n",
      "Step 31\n",
      "Step 32\n",
      "Step 33\n",
      "Step 34\n",
      "Step 35\n",
      "Step 36\n",
      "Step 37\n",
      "Step 38\n",
      "Step 39\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train code\n",
    "\"\"\"\n",
    "max_epochs = 1\n",
    "batch_size = 32\n",
    "embedding_dim = 128\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "num_heads = 4\n",
    "dropout = 0.2\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "test_interval = 21  # Test every 100 steps\n",
    "log_interval = 20\n",
    "\n",
    "model = BiGRUEncoder(len(vocab), embedding_dim, hidden_dim, num_layers=num_layers, dropout=dropout)\n",
    "# model = BiGRUEncoder(len(vocab), embedding_dim, hidden_dim, num_layers=num_layers, dropout=dropout)\n",
    "# model = TransformerEncoder(len(vocab), embedding_dim, num_heads, num_layers * 2, hidden_dim, dropout=dropout)\n",
    "\n",
    "model\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "import random\n",
    "\n",
    "step = 0\n",
    "model.train()\n",
    "max_score = 0.0\n",
    "for epoch in range(max_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{max_epochs}\")\n",
    "    random.shuffle(train_ids)  # Shuffle the training data\n",
    "    if step > 120:\n",
    "        break\n",
    "        \n",
    "    for i in range(0, len(train_ids), batch_size):\n",
    "        if step > 120:\n",
    "            break\n",
    "            \n",
    "        step += 1\n",
    "        print(f\"Step {step}\")\n",
    "        batch_ids = train_ids[i:i + batch_size]\n",
    "        batch_claims = [train_claims[claim_id] for claim_id in batch_ids]\n",
    "        batch_indices = [claim_id_to_train_inidce[claim_id] for claim_id in batch_ids]\n",
    "\n",
    "        # Get claim embeddings\n",
    "        claim_texts = [train_texts_indices[i] for i in batch_indices]\n",
    "        claim_lengths = [len(text) for text in claim_texts]\n",
    "        claim_batch_indices = torch.nn.utils.rnn.pad_sequence([torch.tensor(text) for text in claim_texts], \n",
    "                                                              batch_first=True, padding_value=vocab['<pad>'])\n",
    "        \n",
    "        claim_embeddings = model(claim_batch_indices, claim_lengths)\n",
    "        \n",
    "        norm_claim_embeddings = F.normalize(claim_embeddings, p=2, dim=1)\n",
    "\n",
    "        # Get all positive evidence\n",
    "        evidence_indices = []\n",
    "        pos_evidence_positive_indices = []\n",
    "        for claim in batch_claims:\n",
    "            positive_evidence_indices = []\n",
    "            for evidence_id in claim[\"evidences\"]:\n",
    "                evidence_global_index = evidence_id_to_train_index[evidence_id]\n",
    "                if evidence_global_index not in evidence_indices:\n",
    "                    evidence_indices.append(evidence_global_index)\n",
    "                positive_evidence_indices.append(evidence_indices.index(evidence_global_index))\n",
    "            pos_evidence_positive_indices.append(positive_evidence_indices)\n",
    "        \n",
    "        cur_evidence_indices = [evidence_texts_indices[evidence_indice] for evidence_indice in evidence_indices]\n",
    "\n",
    "        # Get evidence embeddings\n",
    "        evidence_lengths = [len(text) for text in cur_evidence_indices]\n",
    "        evidence_batch_indices = torch.nn.utils.rnn.pad_sequence([torch.tensor(text) for text in cur_evidence_indices], \n",
    "                                                                 batch_first=True, padding_value=vocab['<pad>'])\n",
    "        \n",
    "        evidence_embeddings = model(evidence_batch_indices, evidence_lengths)\n",
    "        norm_evidence_embeddings = F.normalize(evidence_embeddings, p=2, dim=1)\n",
    "\n",
    "        loss = []\n",
    "        for i, claim_embedding in enumerate(norm_claim_embeddings):\n",
    "            pos_evidence_embeddings = norm_evidence_embeddings[torch.tensor(pos_evidence_positive_indices[i])]\n",
    "            neg_evidence_embeddings = norm_evidence_embeddings[torch.tensor([j for j in range(len(evidence_indices)) if j not in pos_evidence_positive_indices[i]])]\n",
    "            \n",
    "            # Compute contrastive loss\n",
    "            loss.append(contrastive_loss(claim_embedding, pos_evidence_embeddings, neg_evidence_embeddings))\n",
    "        loss = torch.mean(torch.stack(loss))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    "        if step % log_interval == 0:\n",
    "            print(f\"Loss: {loss.item()}\")\n",
    "        if step % test_interval == 0:\n",
    "            # Evaluate the model on the dev set\n",
    "            f_score = get_test_f_scores(dev_texts_indices, dev_claims, dev_ids, evidence_texts_indices, evidence_ids, model, batch_size=batch_size)\n",
    "            print(f\"F-score on dev set: {f_score}\")\n",
    "            # Save the model\n",
    "            torch.save(model.state_dict(), f\"model_epoch_{epoch + 1}_step_{step}.pth\")\n",
    "            if f_score > max_score:\n",
    "                max_score = f_score\n",
    "                print(f\"New best F-score: {max_score}\")\n",
    "                torch.save(model.state_dict(), \"best_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzGuzHPE87Ya"
   },
   "source": [
    "# 3.Testing and Evaluation\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6ZVeNYIH9IaL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 394.21it/s]\n",
      "100%|██████████| 3778/3778 [00:43<00:00, 87.83it/s] \n"
     ]
    }
   ],
   "source": [
    "# Load the best model \"best_model.pth\"\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "test_claims_embeddings = generate_all_embeddings(model, test_texts_indices, batch_size=batch_size)\n",
    "test_evidence_embeddings = generate_all_embeddings(model, evidence_texts_indices, batch_size=batch_size*10)\n",
    "\n",
    "norm_test_claim_embeddings = F.normalize(test_claims_embeddings, p=2, dim=1)\n",
    "norm_evidence_embeddings = F.normalize(test_evidence_embeddings, p=2, dim=1)\n",
    "\n",
    "# Compute cosine similarities\n",
    "similarities = torch.matmul(norm_test_claim_embeddings, norm_evidence_embeddings.T)\n",
    "\n",
    "# Get top-k evidence indices for each claim\n",
    "top_k = 5\n",
    "top_k_indices = torch.topk(similarities, top_k, dim=1).indices\n",
    "top_k_indices = top_k_indices.numpy()\n",
    "\n",
    "# Save the results\n",
    "test_claims_ids = list(test_claims.keys())\n",
    "results = test_claims\n",
    "for i, claim_id in enumerate(test_claims_ids):\n",
    "    # Get the evidence indices for the claim\n",
    "    predicted_evidence_indices = top_k_indices[i]\n",
    "    predicted_evidence_indices = [evidence_ids[evidence_index] for evidence_index in predicted_evidence_indices]\n",
    "    \n",
    "    # Store the results\n",
    "    results[claim_id]['evidences'] = predicted_evidence_indices\n",
    "\n",
    "\n",
    "# Save the results to a JSON file\n",
    "output_file = os.path.join(data_dir, \"test_claims_retrieved_lstm.json\")\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mefSOe8eTmGP"
   },
   "source": [
    "## Object Oriented Programming codes here\n",
    "\n",
    "*You can use multiple code snippets. Just add more if needed*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

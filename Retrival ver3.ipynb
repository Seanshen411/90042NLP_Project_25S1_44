{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2025 COMP90042 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the marker, please mention here.*\n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.DataSet Processing\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qvff21Hv8zjk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed 564 evidences shorter than 5\n",
            "Train claims: 1228\n",
            "Dev claims: 154\n",
            "Evidences: 1208263\n",
            "Test claims: 153\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "data_file = \"data\"\n",
        "train_file = os.path.join(data_file, 'train-claims.json')\n",
        "dev_file = os.path.join(data_file, 'dev-claims.json')\n",
        "evidence_file = os.path.join(data_file, 'evidence.json')\n",
        "test_file = os.path.join(data_file, 'test-claims-unlabelled.json')\n",
        "\n",
        "def remove_short_evidences(evidences, min_length=5):\n",
        "    filtered_evidences = {eid: text for eid, text in evidences.items() if len(text) >= min_length}\n",
        "    print(f\"Removed {len(evidences) - len(filtered_evidences)} evidences shorter than {min_length}\")\n",
        "    return filtered_evidences\n",
        "\n",
        "with open(train_file, 'r') as f:\n",
        "    tr_claims = json.load(f)\n",
        "tr_numbers = list(tr_claims.keys())\n",
        "tr_texts = [tr_claims[claim_id]['claim_text'] for claim_id in tr_numbers]\n",
        "claim_number_to_tr_id = {claim_id: i for i, claim_id in enumerate(tr_numbers)}\n",
        "\n",
        "with open(dev_file, 'r') as f:\n",
        "    dev_claims = json.load(f)\n",
        "dev_numbers = list(dev_claims.keys())\n",
        "dev_texts = [dev_claims[claim_id]['claim_text'] for claim_id in dev_numbers]\n",
        "\n",
        "with open(evidence_file, 'r') as f:\n",
        "    evidences = json.load(f)\n",
        "evidences = remove_short_evidences(evidences)\n",
        "evi_numbers = list(evidences.keys())\n",
        "evidences_texts = [evidences[evidence_id] for evidence_id in evi_numbers]\n",
        "evi_number_to_evi_id = {evi_number: i for i, evi_number in enumerate(evi_numbers)}\n",
        "evi_id_to_evi_number = {i: evi_number for i, evi_number in enumerate(evi_numbers)}\n",
        "\n",
        "with open(test_file, 'r') as f:\n",
        "    test_claims = json.load(f)\n",
        "ts_numbers = list(test_claims.keys())\n",
        "ts_texts = [test_claims[claim_id]['claim_text'] for claim_id in ts_numbers]\n",
        "\n",
        "print(\"Train claims:\", len(tr_claims))\n",
        "print(\"Dev claims:\", len(dev_claims))   \n",
        "print(\"Evidences:\", len(evidences))\n",
        "print(\"Test claims:\", len(test_claims))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "#todo test other models\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, max_length=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Model Implementation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to C:\\Users\\Salist\n",
            "[nltk_data]     desk2\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to C:\\Users\\Salist\n",
            "[nltk_data]     desk2\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to C:\\Users\\Salist\n",
            "[nltk_data]     desk2\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#######TFIDF functions#######\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy import sparse\n",
        "import joblib\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def word_tokenize_and_lemmatize(text):\n",
        "    def lemmatize_word(token):\n",
        "        token = lemmatizer.lemmatize(token, pos='v')\n",
        "        token = lemmatizer.lemmatize(token, pos='n') if token != token else token\n",
        "        return token\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [token for token in tokens if token.isalpha() and token not in stopwords.words('english')]\n",
        "    lemmed_tokens = [lemmatize_word(token) for token in tokens]\n",
        "    return lemmed_tokens\n",
        "\n",
        "def save_tfidf_model(text_list, path_name):\n",
        "    vectorizer = TfidfVectorizer(tokenizer=word_tokenize_and_lemmatize, max_features=2000)\n",
        "    text_ids = list(text_list.keys())\n",
        "    text_list = [text_list[id] for id in text_ids]\n",
        "\n",
        "    tfidf_matrix = vectorizer.fit_transform(text_list)\n",
        "    vector_path=str(path_name + \"_vectors.npz\")\n",
        "    model_path=str(path_name + \"_vectorizer.pkl\")\n",
        "    sparse.save_npz(vector_path, tfidf_matrix)\n",
        "    joblib.dump(vectorizer, model_path)\n",
        "    print(f\"Saved TF-IDF vectors to '{vector_path}' and vectorizer to '{model_path}'\")\n",
        "\n",
        "def load_tfidf(path_name):\n",
        "    vector_path=str(path_name + \"_vectors.npz\")\n",
        "    model_path=str(path_name + \"_vectorizer.pkl\")\n",
        "    tfidf_matrix = sparse.load_npz(vector_path)\n",
        "    vectorizer = joblib.load(model_path)\n",
        "    print(f\"Loaded TF-IDF matrix from '{vector_path}' and vectorizer from '{model_path}'\")\n",
        "    return tfidf_matrix, vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#run save tfidf\n",
        "# save_tfidf_model(evidences, \"evidences\")\n",
        "\n",
        "#load tfidf\n",
        "# tfidf_vectors, tfidf_vectorizer = load_tfidf(\"data/evidences\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import json\n",
        "def get_topk_evidence_numbers(tr_claims_vectors, evidences_vectors, k=100):\n",
        "    sim_matrix = cosine_similarity(tr_claims_vectors, evidences_vectors)\n",
        "    topk_evi_num = []\n",
        "    for i in range(sim_matrix.shape[0]):\n",
        "        row = sim_matrix[i]\n",
        "        if k < len(row):\n",
        "            idx = np.argpartition(row, -k)[-k:]\n",
        "            idx = idx[np.argsort(row[idx])[::-1]]\n",
        "        else:\n",
        "            idx = np.argsort(row)[::-1]\n",
        "        cur_topk_indices = idx[:k]\n",
        "        cur_topk_numbers = [evi_id_to_evi_number[j] for j in cur_topk_indices]\n",
        "        topk_evi_num.append(cur_topk_numbers)\n",
        "    print(f\"Collected top {k} evidence ids for each claim, total claims: {len(topk_evi_num)}\")\n",
        "    return topk_evi_num\n",
        "\n",
        "def get_all_filterd_evi_ids(*claims_dicts, topk_evi_num):\n",
        "    evi_nums = set()\n",
        "    for claims in claims_dicts:\n",
        "        for claim in claims.values():\n",
        "            evi_nums.update(claim.get('evidences', []))\n",
        "    for claim in topk_evi_num:\n",
        "        for evi_num in claim:\n",
        "            evi_nums.add(evi_num)\n",
        "    return evi_nums\n",
        "\n",
        "# evidences_vectors, evidences_vectorizer = load_tfidf(\"data/evidences\")\n",
        "# tr_claims_vectors = evidences_vectorizer.transform([tr_claims[id]['claim_text'] for id in tr_numbers])\n",
        "# topk_evi_num = get_topk_evidence_numbers(tr_claims_vectors, evidences_vectors, k=100)\n",
        "# filtered_evi_ids = get_all_filterd_evi_ids(tr_claims, dev_claims, topk_evi_num=topk_evi_num)\n",
        "# print(f\"Filtered evidence ids: {len(filtered_evi_ids)}\")\n",
        "# with open(os.path.join(\"data\", \"topk_evi_num.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "#     json.dump(list(topk_evi_num), f, ensure_ascii=False, indent=2)\n",
        "# with open(os.path.join(\"data\", \"filtered_evi_ids.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "#     json.dump(list(filtered_evi_ids), f, ensure_ascii=False, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered evidence ids: 48302\n"
          ]
        }
      ],
      "source": [
        "with open(\"data/filtered_evi_ids.json\", 'r') as f:\n",
        "    filtered_evi_ids = json.load(f)\n",
        "with open(\"data/topk_evi_num.json\", 'r') as f:\n",
        "    topk_evi_num = json.load(f)\n",
        "#Filter evidences by high similarity from TFIDF\n",
        "filtered_evi_ids = get_all_filterd_evi_ids(tr_claims, dev_claims, topk_evi_num=topk_evi_num)\n",
        "print(f\"Filtered evidence ids: {len(filtered_evi_ids)}\")\n",
        "evi_numbers = list(filtered_evi_ids)\n",
        "evidences_texts = [evidences[evidence_id] for evidence_id in evi_numbers]\n",
        "evi_number_to_evi_id = {evi_number: i for i, evi_number in enumerate(evi_numbers)}\n",
        "evi_id_to_evi_number = {i: evi_number for i, evi_number in enumerate(evi_numbers)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#######sbert functions#######\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def generate_batched_embeddings_ts(model, texts, batch_size=32):\n",
        "    model.eval()\n",
        "    all_embeddings = []\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(texts), batch_size)):\n",
        "            batch_evi_indices = texts[i:i + batch_size]\n",
        "            inputs = tokenizer(batch_evi_indices, padding=True, truncation=True, return_tensors=\"pt\").to(model.device)\n",
        "            outputs = model(**inputs)\n",
        "            batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu()\n",
        "            all_embeddings.append(batch_embeddings)\n",
        "            torch.cuda.empty_cache()\n",
        "    return torch.cat(all_embeddings)\n",
        "\n",
        "#returns f1 for each claim\n",
        "def evaluate_retrival(claims, top_evidence_id):\n",
        "    claims_f1 = []\n",
        "    for i, claim_id in enumerate(claims.keys()):\n",
        "        correct = 0\n",
        "        recall = 0.0\n",
        "        precision = 0.0\n",
        "        fscore = 0.0\n",
        "        \n",
        "        claim = claims[claim_id]\n",
        "        true_evidence_num = claim['evidences']\n",
        "        pred_evidence_num = [evi_numbers[idx] for idx in top_evidence_id[i]]\n",
        "        for true_evidence in true_evidence_num:\n",
        "            true_evidence_id = int(true_evidence.split('-')[1])\n",
        "            if true_evidence_id in pred_evidence_num:\n",
        "                correct += 1\n",
        "        if correct > 0:\n",
        "            recall = correct / len(true_evidence_num)\n",
        "            precision = correct / len(pred_evidence_num[i])\n",
        "            fscore = (2 * precision * recall) / (precision + recall)\n",
        "        claims_f1.append(fscore)\n",
        "    return claims_f1\n",
        "\n",
        "#returns avg f1 for input claims\n",
        "def calc_f1(claim_texts_indices, claims, evidences_text_indices, model, bathch_size=32):\n",
        "    model.eval()\n",
        "\n",
        "    claim_embeddings = generate_batched_embeddings_ts(model, claim_texts_indices, batch_size=bathch_size)\n",
        "    claim_embeddings_norm = F.normalize(claim_embeddings, p=2, dim=1)\n",
        "\n",
        "    evidences_embeddings = generate_batched_embeddings_ts(model, evidences_text_indices, batch_size=bathch_size)\n",
        "    evidences_embeddings_norm = F.normalize(evidences_embeddings, p=2, dim=1)\n",
        "\n",
        "    cos_similarities = torch.matmul(claim_embeddings_norm, evidences_embeddings_norm.T)\n",
        "\n",
        "    top_k_indices = []\n",
        "    similarity_threshold = 0.8\n",
        "    for i in range(cos_similarities.shape[0]):\n",
        "        sim_row = cos_similarities[i]\n",
        "        max_sim = torch.max(sim_row)\n",
        "        indices = torch.where(\n",
        "            (sim_row > similarity_threshold) & ((max_sim - sim_row) < 0.04*max_sim)\n",
        "        )[0].cpu().numpy()\n",
        "        if len(indices) > 5:\n",
        "            top_indices = torch.topk(sim_row, 5).indices.cpu().numpy()\n",
        "            indices = top_indices\n",
        "        elif len(indices) == 0:\n",
        "            indices = torch.topk(sim_row, 3).indices.cpu().numpy()\n",
        "        top_k_indices.append(indices)\n",
        "\n",
        "    claims_f1 = evaluate_retrival(claims, top_k_indices)\n",
        "    model.train()\n",
        "    return np.mean(claims_f1)\n",
        "\n",
        "#get normalized embeddings from model\n",
        "def get_normalized_embeddings(texts, model, tokenizer):\n",
        "    model_inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model(**model_inputs)\n",
        "    embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "    norm_embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "    return norm_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "#returns all evidence indices included in the claim tr\n",
        "def get_real_evidences(batch_claims):\n",
        "    evi_indices = []\n",
        "    claims_pos_evidence_indices = []\n",
        "    for claim in batch_claims:\n",
        "        pos_evi_indices = []\n",
        "        for evi_number in claim[\"evidences\"]:\n",
        "            cur_evi_index = evi_number_to_evi_id[evi_number]\n",
        "            if cur_evi_index not in evi_indices:\n",
        "                evi_indices.append(cur_evi_index)\n",
        "            pos_evi_indices.append(evi_indices.index(cur_evi_index))\n",
        "        claims_pos_evidence_indices.append(pos_evi_indices)\n",
        "    return evi_indices, claims_pos_evidence_indices\n",
        "\n",
        "#return all true pos evi and size of neg evi\n",
        "def get_pos_evi_indices(batch_claims, neg_size=50):\n",
        "    claims_pos_evidence_indices = []\n",
        "    claims_neg_evidence_indices = []\n",
        "    batch_all_evi_indices = []\n",
        "    batch_len = len(batch_claims)\n",
        "    for i in range(batch_len):\n",
        "        claim = batch_claims[i]\n",
        "        pos_evi_indices = []\n",
        "        for evi_number in claim[\"evidences\"]:\n",
        "            cur_evi_index = evi_number_to_evi_id[evi_number]\n",
        "            if cur_evi_index not in batch_all_evi_indices:\n",
        "                batch_all_evi_indices.append(cur_evi_index)\n",
        "            pos_evi_indices.append(batch_all_evi_indices.index(cur_evi_index))\n",
        "        claims_pos_evidence_indices.append(pos_evi_indices)\n",
        "\n",
        "        neg_evi_number = random.sample(topk_evi_num[i], neg_size)\n",
        "        random_neg_evi_indices = []\n",
        "        for evi_number in neg_evi_number:\n",
        "            if evi_number not in claim[\"evidences\"]:\n",
        "                cur_evi_index = evi_number_to_evi_id[evi_number]\n",
        "                if cur_evi_index not in batch_all_evi_indices:\n",
        "                    batch_all_evi_indices.append(cur_evi_index)\n",
        "                random_neg_evi_indices.append(batch_all_evi_indices.index(cur_evi_index))\n",
        "        claims_neg_evidence_indices.append(random_neg_evi_indices)\n",
        "    return claims_pos_evidence_indices, claims_neg_evidence_indices, batch_all_evi_indices\n",
        "\n",
        "#loss based on cosine similarity of pos and neg evidence\n",
        "def contrastive_loss(claim_embedding, pos_evi_embeddings, neg_evi_embeddings, temperature=0.1):\n",
        "    \"\"\"Compute contrastive loss for a claim\"\"\"\n",
        "    pos_sim = torch.exp(torch.matmul(claim_embedding, pos_evi_embeddings.T) / temperature).sum()\n",
        "    neg_sim = torch.exp(torch.matmul(claim_embedding, neg_evi_embeddings.T) / temperature).sum()\n",
        "\n",
        "    loss = -torch.log(pos_sim / (pos_sim + neg_sim))\n",
        "    return loss.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#########RUN ON COLAB##########\n",
        "########Training setup#########\n",
        "import random\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "max_epochs = 10  ######Change Later######\n",
        "max_steps = 100  ######Change Later######\n",
        "batch_size = 20\n",
        "learning_rate = 1e-5\n",
        "test_period = 100\n",
        "log_period = 20\n",
        "neg_size = 50\n",
        "\n",
        "model= AutoModel.from_pretrained(model_name)\n",
        "# model = model.cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "num_warmup_steps = int(0.1 * max_steps)\n",
        "scheduler = get_cosine_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=max_steps\n",
        ")\n",
        "\n",
        "def save_training_log(loss_record, f1_record):\n",
        "    params = {\n",
        "        \"batch_size\": batch_size,\n",
        "        \"model_name\": model_name,\n",
        "        \"base_lr\": learning_rate,\n",
        "        \"negative_evidence_size\": neg_size\n",
        "    }\n",
        "    log = {\n",
        "        \"params\": params,\n",
        "        \"loss_record\": loss_record,\n",
        "        \"f1_record\": f1_record\n",
        "    }\n",
        "    log_name = f\"{model_name.split('/')[1]}_dev_log.json\"\n",
        "    print(f\"Saving training log to results/{log_name}\")\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "    with open(os.path.join(\"results\", log_name), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(log, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#########RUN ON COLAB##########\n",
        "step = 0\n",
        "model.train()\n",
        "max_f1 = 0.0\n",
        "loss_record = []\n",
        "f1_record = []\n",
        "for epoch in range(max_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{max_epochs}\")\n",
        "    random.shuffle(tr_numbers)\n",
        "\n",
        "    for i in range(0, len(tr_numbers), batch_size):\n",
        "        if step > max_steps:\n",
        "            break\n",
        "        step += 1\n",
        "        if step % 10 == 0:\n",
        "            print(f\"Step {step}\")\n",
        "        batch_claim_ids = tr_numbers[i:i + batch_size] # claim ids\n",
        "        batch_claims = [tr_claims[claim_id] for claim_id in batch_claim_ids]\n",
        "        batch_tr_indices = [claim_number_to_tr_id[claim_id] for claim_id in batch_claim_ids] #claims' train indices\n",
        "        \n",
        "        claim_text = [tr_texts[i] for i in batch_tr_indices]\n",
        "        norm_claim_embeddings = get_normalized_embeddings(claim_text, model, tokenizer)\n",
        "\n",
        "        #neg 1\n",
        "        # all_real_evi_id, pos_evi_id = get_real_evidences(batch_claims)\n",
        "        # batch_all_evi_ids = []\n",
        "        # for evi_number in topk_evi_number:\n",
        "        #     batch_all_evi_ids\n",
        "        # batch_evi_texts = [evidences_texts[i] for i in batch_all_evi_ids]\n",
        "\n",
        "        #neg 2\n",
        "        pos_evi_id, neg_evi_id, batch_all_evi_ids = get_pos_evi_indices(batch_claims, neg_size) #modify\n",
        "        batch_evi_texts = [evidences_texts[i] for i in batch_all_evi_ids]\n",
        "        \n",
        "        norm_evi_embeddings = get_normalized_embeddings(batch_evi_texts, model, tokenizer)\n",
        "        loss = []\n",
        "        for i, claim_embedding in enumerate(norm_claim_embeddings):\n",
        "            pos_evi_embedding = norm_evi_embeddings[torch.tensor(pos_evi_id[i])]\n",
        "            #todo adjust negtive evidence, more negative evidence use tfidf & some random\n",
        "            #todo try to use model prediction as pos neg evidences\n",
        "            \n",
        "            #neg evi 1: postive evidence of other claims \n",
        "            # neg_evidences = [j for j in range(len(batch_evi_texts)) if j not in pos_evi_id[i]]\n",
        "            # neg_evi_embedding = norm_evi_embeddings[torch.tensor(neg_evidences)]\n",
        "            \n",
        "            #neg evi 2: high tfidf but not true evidence\n",
        "            neg_evi_embedding = norm_evi_embeddings[torch.tensor(neg_evi_id[i])]\n",
        "\n",
        "            loss.append(contrastive_loss(claim_embedding, pos_evi_embedding, neg_evi_embedding))\n",
        "        loss = torch.mean(torch.stack(loss))\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        torch.cuda.empty_cache()\n",
        "        if step % log_period == 0:\n",
        "            loss_record.append(loss.item())\n",
        "            print(f\"Step {step}, Loss: {loss.item()}\")\n",
        "        if step % test_period == 0 and step > max_steps*0.1:\n",
        "            print(\"Evaluating on dev set...\")\n",
        "            dev_f1 = calc_f1(dev_texts, dev_claims, evidences_texts, model)\n",
        "            avg_f1 = np.mean(dev_f1)\n",
        "            f1_record.append(avg_f1)\n",
        "            print(f\"Avg F1 on dev set: {avg_f1}, History Best: {max_f1}\")\n",
        "            if avg_f1 > max_f1:\n",
        "                max_f1 = avg_f1\n",
        "                print(f\"New best F1: {max_f1}, model saved.\")\n",
        "                os.makedirs(\"results\", exist_ok=True)\n",
        "                torch.save(model.state_dict(), os.path.join(\"results\", \"best_model.pth\"))\n",
        "                \n",
        "save_training_log(loss_record, f1_record)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\", weights_only=True))\n",
        "model.eval()\n",
        "\n",
        "ts_claims_embeddings = generate_batched_embeddings_ts(model, ts_texts, batch_size=batch_size)\n",
        "ts_evi_embeddings = generate_batched_embeddings_ts(model, evidences_texts, batch_size=batch_size*10)\n",
        "norm_ts_claim_embeddings = F.normalize(ts_claims_embeddings, p=2, dim=1)\n",
        "norm_evi_embeddings = F.normalize(ts_evi_embeddings, p=2, dim=1)\n",
        "\n",
        "similarities = torch.matmul(norm_ts_claim_embeddings, norm_evi_embeddings.T)\n",
        "\n",
        "top_k_indices = []\n",
        "similarity_threshold = 0.8\n",
        "for i in range(similarities.shape[0]):\n",
        "    sim_row = similarities[i]\n",
        "    max_sim = torch.max(sim_row)\n",
        "    indices = torch.where(\n",
        "        (sim_row > similarity_threshold) & ((max_sim - sim_row) < 0.04*max_sim)\n",
        "    )[0].cpu().numpy()\n",
        "    if len(indices) == 0:\n",
        "        indices = torch.topk(sim_row, 3).indices.cpu().numpy()\n",
        "    top_k_indices.append(indices)\n",
        "\n",
        "# Save the results\n",
        "test_claims_ids = list(test_claims.keys())\n",
        "results = test_claims\n",
        "for i, claim_id in enumerate(test_claims_ids):\n",
        "    # Get the evidence indices for the claim\n",
        "    pred_evi_ids = top_k_indices[i]\n",
        "    pred_evi_numbers = [evi_numbers[evidence_id] for evidence_id in pred_evi_ids]\n",
        "    \n",
        "    # Store the results\n",
        "    results[claim_id]['evidences'] = pred_evi_numbers\n",
        "    results[claim_id]['claim_label'] = \"SUPPORTS\"\n",
        "\n",
        "\n",
        "# Save the results to a JSON file\n",
        "output_file = os.path.join(\"result\", \"test_claims_retrieved_bert.json\")\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(results, f, indent=4)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "GroupID44_comp90042_project_2025.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
